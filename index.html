
<!DOCTYPE html>

<html>

<head>
   <style>
      td, th {
        border: 0px solid black;          
        }
      img{
   padding: 5px;
}
      </style>

  <title>IRG-SFDA</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  <link rel="shortcut icon" href="./static/images/irg/jhu_web.png" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
  <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

<script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>

<style>
    body {
        font-family: 'Google Sans', sans-serif;
    }
    .top-nav {
        display: flex;
        justify-content: center;
        align-items: center;
        padding: 0.5rem; /* Reduced padding */
        background-color: #ffffff;
    }
    .nav-center {
        display: flex;
        align-items: center;
        gap: 10px; /* Reduced gap */
    }
    .home-icon {
        font-size: 1.3rem; /* Slightly reduced size */
        color: #4a4a4a;
        text-decoration: none;
    }
    .dropdown {
        position: relative;
        display: inline-block;
    }
    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f9f9f9;
        min-width: 160px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        z-index: 1;
        left: 50%;
        transform: translateX(-50%);
    }
    .dropdown:hover .dropdown-content {
        display: block;
    }
    .dropdown-content a {
        color: black;
        padding: 12px 16px;
        text-decoration: none;
        display: block;
        text-align: center;
    }
    .dropdown-content a:hover {
        background-color: #f1f1f1;
    }
    .publication-title {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        margin-top: 1rem; /* Reduced top margin */
        margin-bottom: 1rem;
    }
    .publication-authors {
        font-size: 1.2rem;
        text-align: center;
        margin-bottom: 1rem;
    }
    .author-block {
        display: inline-block;
        margin-right: 10px;
    }
</style>

<body>

   <nav class="top-nav">
    <div class="nav-center">
        <a href="#" class="home-icon">üè†</a>
        <div class="dropdown">
            <span>More Research ‚ñº</span>
            <div class="dropdown-content">
                <a href="https://vibashan.github.io/possam-web/" target="_blank">PosSAM</a>
                <a href="https://kartik-3004.github.io/facexformer_web/" target="_blank">FaceXformer</a>
                <a href="https://vibashan.github.io/ovis-web/" target="_blank">Mask-Free OVIS</a>
                <a href="https://viudomain.github.io/mega-web/" target="_blank">MeGA-CDA</a>
                <a href="https://viudomain.github.io/tt-sfuda-web/" target="_blank">TT SFDA</a>
            </div>
        </div>
    </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Instance Relation Graph Guided Source-Free
            Domain Adaptive Object Detection</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://vibashan.github.io/">Vibashan VS</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=9dhBHuAAAAAJ&hl=en">Poojan Oza</a><sup>1</sup>,
            </span>
            <span class="author-block"></span>
              <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Johns Hopkins University,</span>
          </div>
         
         <div class="column has-text-centered">
            <a href="as">CVPR 2023</a>
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/VS_Instance_Relation_Graph_Guided_Source-Free_Domain_Adaptive_Object_Detection_CVPR_2023_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <img src="./static/images/irg/pdf.svg" alt="PDF icon" width="32" height="32">
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/Vibashan/irg-sfda"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <img src="./static/images/irg/github.svg" alt="GitHub icon" width="32" height="32">
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Unsupervised Domain Adaptation (UDA) is an effective approach to tackle the issue of domain shift. Specifically, UDA methods try to align the source and 
            target representations to improve generalization on the target domain. Further, UDA methods work under the assumption that the source data is accessible
            during the adaptation process. However, in real-world scenarios, the labelled source data is often restricted due to privacy regulations, data transmission
            constraints, or proprietary data concerns. The Source-Free Domain Adaptation (SFDA) setting aims to alleviate these concerns by adapting a source-trained 
            model for the target domain without requiring access to the source data. In this paper, we explore the SFDA setting for the task of adaptive object detection.
            To this end, we propose a novel training strategy for adapting a source-trained object detector to the target domain without source data. More precisely,
            we design a novel contrastive loss to enhance the target representations by exploiting the objects relations for a given target domain input. These object
            instance relations are modelled using an Instance Relation Graph (IRG) network, which are then used to guide the contrastive representation learning. 
            In addition, we utilize a student-teacher based knowledge distillation strategy to avoid overfitting to the noisy pseudo-labels generated by the 
            source-trained model. Extensive experiments on multiple object detection benchmark datasets show that the proposed approach is able to efficiently 
            adapt source-trained object detectors to the target domain, outperforming previous state-of-the-art domain adaptive detection methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Motivation</h2>
              <div class="content has-text-justified">
                <h5 class="subtitle has-text-centered"></h5> 
                <img src="./static/images/irg/Intro.svg" alt="" border=0 height=500 width=1500></img></
              <p>
                Supervised training of detection model on the source domain. Right:
                Source-Free Domain Adaptation (SFDA) setup, i.e., the source-trained model is
                adapted to the target domain in the absence of source data with pseudo-label self-
                training and proposed Instance Relation Graph (IRG) network guided contrastive loss.
              </p> 
    
              <center> Free-RPN Contrastive views</center>
                <img src="./static/images/irg/motive.svg" alt="" border=0 height=500 width=1500></img></
              <p>
                (a) Class agnostic object proposals generated by Region Proposal Network
                (RPN). (b) Cropping out RPN proposals will provide multiple contrastive views of
                an object instance. We utilize this to improve target domain feature representations
                through RPN-view contrastive learning. However as RPN proposals are class agnostic,
                it is challenging to form positive (same class)/negative pairs (different class), which is
                essential for CRL.
              </p> 
          
              </div>
           </div>
          </div>
        </div>
    </section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            <h5 class="subtitle has-text-centered"></h5> 

          <center>Overview of the proposed framework</center>
            <img src="./static/images/irg/Archi.svg" alt="" border=0 height=500 width=1500></img></
          <p>
            We follow a student-teacher framework for
            the detector model training. The proposed Instance Relation Graph (IRG) network
            models the relation between the object proposals generated by the detector. Using
            the inter-proposal relations learned by IRG, we generate pairwise labels to identify
            positive/negative pairs for contrastive learning. The IRG network is regularized with
            distillation loss between student and teacher model.
          </p> 

      
          </div>
       </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
          <div class="content has-text-justified">
            <h5 class="subtitle has-text-centered"></h5> 
            <img src="./static/images/irg/relation mat.svg" alt="" border=0 height=500 width=1500></img></
          <p>
            Relation matrix analysis for 25 proposal RoI features before and after passing
            through IRG network and corresponding masked instance pairwise labels. We can ob-
            serve the IRG network models the relationship between the proposal, which maximizes
            the similarity between similar proposals and vice versa for dissimilar proposals.
          </p> 

      
          </div>
       </div>
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    
    <pre><code>
    @inproceedings{vs2023instance,
  title={Instance relation graph guided source-free domain adaptive object detection},
  author={VS, Vibashan and Oza, Poojan and Patel, Vishal M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3520--3530},
  year={2023}
}
    </code></pre>
  </div>
</section>

<section class="section" >
  <div class="container is-max-desktop content">
    <h5 class="title">Website Template taken from <span class="author-block">
              <a href="https://nerfies.github.io/" target="_blank">Nerfies</a></h5>

  </div>
</section>

<script>
    const viewers = document.querySelectorAll(".image-compare");
    viewers.forEach((element) => {
        let view = new ImageCompare(element, {
            hoverStart: true,
            addCircle: true
        }).mount();
    });

    $(document).ready(function () {
        var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
            lineNumbers: false,
            lineWrapping: true,
            readOnly: true
        });
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    });
</script>
</body>
</html>
